---
title: 量化
---

[\*在线运行 vLLM 入门教程：零基础分步指南](https://app.hyper.ai/console/public/tutorials/rUwYsyhAIt3?utm_source=vLLM-CNdoc&utm_medium=vLLM-CNdoc-V1&utm_campaign=vLLM-CNdoc-V1-25ap)

量化通过牺牲模型精度来换取更小的内存占用，从而使得大型模型能够在更广泛的设备上运行。

## 目录

- [支持硬件](/docs/features/quantization/supported_hardware)
- [AutoAWQ](/docs/features/quantization/auto_awq)
- [BitsAndBytes](/docs/features/quantization/bnb)
- [GGUF](/docs/features/quantization/gguf)
- [INT4 W4A16](/docs/features/quantization/int4)
- [INT8 W8A8](/docs/features/quantization/int8)
- [FP8 W8A8](/docs/features/quantization/fp8)
- [量化 KV 缓存](/docs/features/quantization/quantized_kvcache)
